# Pods and Configuration

## **# Application Configuration**

We can store information in the format of Key=Value using **ConfigMaps**

Also, there are **Secrets** in which we can store data, but they are designed for sensitive data, such as password or API Keys.

## **Environment Variables**

In the Pod spec, to use the configmap for the key-values as environment variables, we do:

```yaml
spec:
    containers:
    - ...
        env:
        - name: ENVVAR
            valueFrom:
                configMapKeyRef:
                    name: my-configmap
                    key: mykey
```

## **# Configuration volumes (mounted volumes)**

We can instead of take keys and values from configmaps into the pods, mount the whole configmap, as a whole file.

**OBS**: Each top-level key in the configuration data will appear as a file containin all keys below that top-level key

```yaml
...
volumes:
- name: secret-vol
  secret:
    secretName: my-secret
```

**QUESTION:** Can I give an arbitrary path? Will the whole directory structure be created for me if I just mention it in the mountPath?

**A:** Mounting as volumes creates the directory you mention in the volumeMounts:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: volume-pod
spec:
  containers:
  - name: busybox
    image: busybox
    command: ['sh', '-c', 'while true; do sleep 3600; done']
    volumeMounts:
    - name: configmap-volume
      mountPath: /etc/config/test/longer/path/configmap
    - name: secret-volume
      mountPath: /etc/config/test/another/longer/path/for/the/secret
  volumes:
  - name: configmap-volume
    configMap:
      name: my-configmap
  - name: secret-volume
    secret:
      secretName: my-secret
```

yelds, once up:

```bash
/etc/config # find . -type d
.
./test
./test/another
./test/another/longer
./test/another/longer/path
./test/another/longer/path/for
./test/another/longer/path/for/the
./test/another/longer/path/for/the/secret
./test/another/longer/path/for/the/secret/..2021_05_05_10_39_17.745374849
./test/longer
./test/longer/path
./test/longer/path/configmap
./test/longer/path/configmap/..2021_05_05_10_39_17.443461418
```

## **# Resources and Requests**

**Resource request** allows a definition of how much CPU/Mem will be required for the pod. _kube-scheduler_ will then attempt to find a node where such requirements are fullfiled

Be aware that the resource request only affects scheduling. The pod will not necessarily consume that amount of cpu/mem. It can consume even less!

**OBS:** _CPU_ is measured in **_CPU units_ (1/1000)** and _Memory_ in _bytes_

**QUESTION:** Is there a way to request _GPU_ the same fashion we do for CPU/Mem?

**A:** Yes, [Here it is explained](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: cuda-vector-add
spec:
  restartPolicy: OnFailure
  containers:
    - name: cuda-vector-add
      # https://github.com/kubernetes/kubernetes/blob/v1.7.11/test/images/nvidia-cuda/Dockerfile
      image: "k8s.gcr.io/cuda-vector-add:v0.1"
      resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
```

**Resource limits** on the other hand provide a way to cap the amount of CPU/Mem that a Pod can use. 

The entity/component enforcing that those limits are respected is the container runtime (Docker, containerd, ...)

**OBS:** Be aware that depending on the container runtime that is chosen, the pod can be terminated if it attempts to use more memory/cpu that the limits. Docker throttles cpu and kill the process if memory limit is attempted to be surpassed

**QUESTION:** What container runtime has this behavior?