# Pods and Configuration

## **# Application Configuration**

We can store information in the format of Key=Value using **ConfigMaps**

Also, there are **Secrets** in which we can store data, but they are designed for sensitive data, such as password or API Keys.

## **Environment Variables**

In the Pod spec, to use the configmap for the key-values as environment variables, we do:

```yaml
spec:
    containers:
    - ...
        env:
        - name: ENVVAR
            valueFrom:
                configMapKeyRef:
                    name: my-configmap
                    key: mykey
```

## **# Configuration volumes (mounted volumes)**

We can instead of take keys and values from configmaps into the pods, mount the whole configmap, as a whole file.

**OBS**: Each top-level key in the configuration data will appear as a file containin all keys below that top-level key

```yaml
...
volumes:
- name: secret-vol
  secret:
    secretName: my-secret
```

**QUESTION:** Can I give an arbitrary path? Will the whole directory structure be created for me if I just mention it in the mountPath?

**A:** Mounting as volumes creates the directory you mention in the volumeMounts:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: volume-pod
spec:
  containers:
  - name: busybox
    image: busybox
    command: ['sh', '-c', 'while true; do sleep 3600; done']
    volumeMounts:
    - name: configmap-volume
      mountPath: /etc/config/test/longer/path/configmap
    - name: secret-volume
      mountPath: /etc/config/test/another/longer/path/for/the/secret
  volumes:
  - name: configmap-volume
    configMap:
      name: my-configmap
  - name: secret-volume
    secret:
      secretName: my-secret
```

yelds, once up:

```bash
/etc/config # find . -type d
.
./test
./test/another
./test/another/longer
./test/another/longer/path
./test/another/longer/path/for
./test/another/longer/path/for/the
./test/another/longer/path/for/the/secret
./test/another/longer/path/for/the/secret/..2021_05_05_10_39_17.745374849
./test/longer
./test/longer/path
./test/longer/path/configmap
./test/longer/path/configmap/..2021_05_05_10_39_17.443461418
```

## **# Resources and Requests**

**Resource request** allows a definition of how much CPU/Mem will be required for the pod. _kube-scheduler_ will then attempt to find a node where such requirements are fullfiled

Be aware that the resource request only affects scheduling. The pod will not necessarily consume that amount of cpu/mem. It can consume even less!

**OBS:** _CPU_ is measured in **_CPU units_ (1/1000)** and _Memory_ in _bytes_

**QUESTION:** Is there a way to request _GPU_ the same fashion we do for CPU/Mem?

**A:** Yes, [Here it is explained](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: cuda-vector-add
spec:
  restartPolicy: OnFailure
  containers:
    - name: cuda-vector-add
      # https://github.com/kubernetes/kubernetes/blob/v1.7.11/test/images/nvidia-cuda/Dockerfile
      image: "k8s.gcr.io/cuda-vector-add:v0.1"
      resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
```

**Resource limits** on the other hand provide a way to cap the amount of CPU/Mem that a Pod can use. 

The entity/component enforcing that those limits are respected is the container runtime (Docker, containerd, ...)

**OBS:** Be aware that depending on the container runtime that is chosen, the pod can be terminated if it attempts to use more memory/cpu that the limits. Docker throttles cpu and kill the process if memory limit is attempted to be surpassed

**QUESTION:** What container runtime has this boehavior?

## **# Multi-Container pods**

We can have multiple containers in the same pods, even though this is not recommended.

The multiple containers inside a pod share few resources:
* **Network**: making it possible for pods to access ports that are not even exposed to the cluster.
* **Storage**: We can define a volume in a pod and several containers can mount it

Usage example:  

Lets say your application only writes logs to a file and not stdout, where the pod would be looking for the logs. In this case, if we want to see logs in pod, we can:
- Mount a volume
- Put another container up, just streaming the log file content to stdout

This other pod is also known as _sidecar_'

### **Init-containers**

init-containers runs once until completion while a pod is at a startup.  
A Pod can have several init containers. One after the other.

Usage example:
- Good to offload tasks from the main container to others, leaving it lighter and more secure.
- Handle password handle
- Populate data from a shared volume at startup
- Communicate to external service (Register or something)
**QUESTION:** What container runtime has this behavior?

## **# Pod Health**

### **# Probes**
#### **Container Health**

There are several features in kubernetes that allow us and the kubernetes itself to manage and act upon the Pod health.  
To accurately do it, k8s needs to know if the Pod is healthy or not. For that the probes exist.

#### **Liveness Probes**

Automatically check if the container is in a healthy state, if it is "alive".

#### **Startup Probes**

The difference between _startup probes_ and _liveness probes_ is that startup only run at startup whereas the liveness keeps on running as long as the pod is there.

This probe is used to determine when the app container has successfully started up. 

These are good for legacy apps that take time to get up.

#### **Readiness Probes**

This probe is used to know when the app container is ready to serve requests. If the pod is not ready, traffic is not sent to the Pod.

### **# Restart Policies**

K8s has the ability to restart Pods that fail to remain healthy.  
There are several behaviors that can be followed to manage the restart.

Restart policies are important for applications that want to claim the self-healing aspect.

Possible restart policies:
* Always (default)  
  Containers will be restarted if they stop, even if they completed successfully.  
  Used in applications that should always be running
* OnFailure  
  Restart containers only if the container becomes unhealthy or exists with error code.  
  Should be used by appls that  should run once and succeed.
* Never  
  No mather what happens, pod is never restarted.  
  Should be used for apps that should run once and never again
