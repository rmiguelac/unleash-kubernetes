# Kubernetes Components

[Official documentation](https://kubernetes.io/docs/concepts/overview/components/)

## **Control Plane**

Makes global decisions about the cluster (schedule, detect and respond to cluster events).  
Usually, no more containers run alongside the control plane.

### **# kube-apiserver**

[Official Kubernetes API documentation](https://kubernetes.io/docs/concepts/overview/kubernetes-api/)

Serves the kubernetes API, the primary interface to control plane and the cluster itself.
```kubectl``` will make use of this to interact with the cluster.

Responsible for:
* authenticate user
* validate request
* Retrieve data
* Update ETCD
* Scheduler
* Kubelet

**QUESTION:** What happens if I scale it down to 0 across all nodes? How can I brige it up again?

**OBS:** Only component that interacts directly with ETCD.

It is distributed as a binary in the kubernetes release page

### **# Etcd**

Backend key-value data store for the cluster. Provides HA distributed storage for all data relating to the state of the cluster
Issuing ```kubectl``` commands will go to **kube-api-server** which will then go to **etcd** to read/write information

**QUESTION:** As said in the official documentation, we should have a backup plan for the etcd data. [How?](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster) 

**QUESTION:** As said in the officual documentation, "_if_ we're using etc as backing store", which means there are others?

Stores information about nodes, pods, configs, secrets, accounts, rolebindings and others...

Every change is update to the etcd server and only once it happens the update/creation is considered done.

**OBS:** only direct interaction is from kube-apiserver

### **# kube-scheduler**

Handles _scheduling_, the process of reading what is defined in POD and selecting a node that matches given criteria as well as availability to then schedule the pod there.

**OBS:** does not actually put pod in node, just maps that X pod should be in Y node. The action is taken by ```kubelet```

The flow here, once we run ```kubectl apply -f deployment.yaml```, most likely is:

```flow
kube-api-server > etcd > kube-api-server > kube-scheduler > kube-api-server > etcd > kube-api-server > output
```

Factors taken into account for scheduling include:

* individual and collective resource requirements
* hardware/software/policy constraints
* affinity and anti-affinity specifications
* data locality
* inter-workload interference
* deadlines

**QUESTION:** What are those requirements??

can be installed as a service by downloading the binary and running it as a service

### **# kube-controller-manager**

Has multiple controllers running in a single process. Handles bunch of stuff:

* **Node controller**: notice and react to nodes going down - 5s info taken from kube-apiserver (--node-monitor-period)
if stops receiveing heartbets from nodes, the bad node is marked as unreachable (40s after bad heartbeat - --node-monitor-grace-period). After 5m (--node-eviction-timeout), if node is not up, pods are moved to other nodes

* **job controller**: watch job objects that represents one-off tasks, creates the pod for it 'till completion
* **Replication-controller**: desired number of replicas (replicaSets) are running
* **endpoints controller**: populates endpoint objects (Joins services and pods)
    **QUESTION:** Why not the kube-proxy here? Or this controls it and delegates to kube-proxy?
* service account & token controllers: Create default accounts and API access tokens for new namespaces

seems like there is a control for each item we can list in api-resources. True?

**QUESTION:** What does it exactly do? When is it called? What happens if I scale it down or it malfunctions?

_The kubelet doesn't manage containers which were not created by Kubernetes_

kube-controller-manager can be downloaded, extracted and run as a service in the master node if installed the hard way.

### **# cloud-controller-manager**

Used to interface to/from cloud providers. Use when k8s cluster is integrated with cloud platform stuff. Most likely used in AKS/EKS... 

As per official documentation _"If you are running Kubernetes on your own premises, or in a learning environment inside your own PC, the cluster does not have a cloud controller manager."_

## **Nodes**

A VM (most-likely) that is a part of the cluster.  
Also known as _worker machines_

### **kubelet**

Kubernetes agent that runs on each node.  
Communicates with control plane and makes sure everything is as expected, meaning that pods are running where/how they are supposed to be.

**OBS:** kubeadm **DOES NOT** deploy kubelet!

**kubelet** also has to check pod status and report them to the control plane.

One more thing to know abou the kubelet is that it has a component inside that is called _cadvisor_, or container advisor. That cdavisor is responsible for collecting performance metrics and exposing them through the kubelet.

### **# container runtime**

Good thing to know is that kubernetes support multiple different implementations of conteriner runtimes - **Docker**, **CRI-O** and **containerd** are examples.   
This is what enables containers to actually run in the node.

(*) Not acually part of the kubernetes but is a requirement that needs to be running in each node.  

### **kube-proxy**

Network proxy.  
Also needs to run in each node of the cluster.  
Implements part of the Service concept.
Provides network rules on nodes. These allow network comm. to Pods from network sessions inside or outside of the cluster.

Installation: download binary, extract and run as a service.
Kubeadm installs it as a daemonset

## **Addons**

Addons use k8s features to implement cluster features.  
Since they provide cluster-level features, namespaced resources for addons belong within the **kube-system** namespace

### **DNS**

all k8s clusters should have a _cluster DNS_.
Cluster DNS is a DNS server, in addition to other DNS server(s) in the environment, which serves DS records for k8s services.

Containers started by K8s automatically include this DNS server in their DNS searches.

### **Web UI (Dashboard)**

General purpose, web-base UI for K8s clusters.  
Allows users to manage and troubleshoot applications running in the cluster, as well as the cluster itself.

### **Container Resource Monitoring**

Records generic time-series metrics about containers in a central database and provides a UI for browsing that data.

### **Cluster-level logging**

Mechanism respondible for saving container logs to a central log store with search/browsing interface.